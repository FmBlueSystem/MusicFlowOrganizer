#!/usr/bin/env python3
"""
Error Recovery & Resilience Testing Suite
=========================================
Tests cr√≠ticos para estabilidad profesional en condiciones adversas.

PRIORIDAD: M√ÅXIMA - Para uso profesional de DJs sin interrupciones

Tests incluidos:
1. File System Disruption (discos desconectados, permisos)
2. Process Interruption Recovery (crashes, kill signals)
3. Database Corruption Handling (MixIn Key DB da√±ada)
4. Memory Pressure Handling (sistema con poca memoria)
5. Network/External Dependencies Failure
6. Partial Analysis Recovery (continuar desde donde se qued√≥)
"""

import sys
import os
import time
import shutil
import signal
import sqlite3
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import tempfile
import subprocess

# Add the src directory to the path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from core.mixinkey_integration import MixInKeyIntegration
from core.performance_manager import PerformanceManager

class ErrorRecoveryResilienceTester:
    """
    Suite completa de tests de recuperaci√≥n de errores y resiliencia.
    Dise√±ada para validar estabilidad profesional bajo condiciones adversas.
    """
    
    def __init__(self):
        self.test_results = {
            'file_system_disruption': {},
            'process_interruption': {},
            'database_corruption': {},
            'memory_pressure': {},
            'external_dependencies': {},
            'partial_recovery': {}
        }
        
        # Create test workspace
        self.test_workspace = Path(tempfile.mkdtemp(prefix="musicflow_test_"))
        
        # Error simulation capabilities
        self.error_scenarios = [
            'disk_disconnection',
            'permission_denied', 
            'database_corruption',
            'memory_exhaustion',
            'process_kill',
            'partial_analysis'
        ]
    
    def run_all_resilience_tests(self):
        """Ejecuta todos los tests de resiliencia priorizados."""
        
        print("üõ°Ô∏è  ERROR RECOVERY & RESILIENCE TESTING SUITE")
        print("=" * 60)
        print("üéØ PRIORIDAD: Estabilidad Profesional bajo Condiciones Adversas")
        
        try:
            # Test 1: File System Disruption (CR√çTICO)
            print(f"\n1Ô∏è‚É£ FILE SYSTEM DISRUPTION TESTING")
            print("-" * 50)
            self.test_file_system_disruption()
            
            # Test 2: Database Corruption Handling (CR√çTICO)
            print(f"\n2Ô∏è‚É£ DATABASE CORRUPTION HANDLING")
            print("-" * 50)
            self.test_database_corruption_handling()
            
            # Test 3: Process Interruption Recovery (CR√çTICO)
            print(f"\n3Ô∏è‚É£ PROCESS INTERRUPTION RECOVERY")
            print("-" * 50)
            self.test_process_interruption_recovery()
            
            # Test 4: Memory Pressure Handling (ALTO)
            print(f"\n4Ô∏è‚É£ MEMORY PRESSURE HANDLING")
            print("-" * 50)
            self.test_memory_pressure_handling()
            
            # Test 5: External Dependencies Failure (ALTO)
            print(f"\n5Ô∏è‚É£ EXTERNAL DEPENDENCIES FAILURE")
            print("-" * 50)
            self.test_external_dependencies_failure()
            
            # Test 6: Partial Analysis Recovery (MEDIO)
            print(f"\n6Ô∏è‚É£ PARTIAL ANALYSIS RECOVERY")
            print("-" * 50)
            self.test_partial_analysis_recovery()
            
            # Generate resilience report
            self.generate_resilience_report()
            
        finally:
            # Cleanup test workspace
            try:
                shutil.rmtree(self.test_workspace)
            except:
                pass
    
    def test_file_system_disruption(self):
        """Test 1: Manejo de disrupciones del sistema de archivos."""
        
        try:
            print("üíæ Testing file system disruption scenarios...")
            
            # Test 1.1: Missing Files During Analysis
            print("   üîç Test 1.1: Missing Files During Analysis")
            
            # Create temporary files that will "disappear"
            temp_files = []
            for i in range(5):
                temp_file = self.test_workspace / f"test_track_{i}.mp3"
                temp_file.write_bytes(b"fake_audio_data")
                temp_files.append(str(temp_file))
            
            # Start analysis
            performance_manager = PerformanceManager(max_workers=2)
            
            # Remove files during analysis to simulate disconnection
            def remove_files_during_analysis():
                time.sleep(0.1)  # Let analysis start
                for temp_file in temp_files[2:]:  # Remove some files mid-analysis
                    try:
                        Path(temp_file).unlink()
                    except:
                        pass
            
            removal_thread = threading.Thread(target=remove_files_during_analysis)
            removal_thread.start()
            
            # Run analysis and see how it handles missing files
            start_time = time.time()
            try:
                results = performance_manager.process_library(temp_files, use_mixinkey=False)
                processing_time = time.time() - start_time
                
                processed_count = results.get('processed_files', 0)
                failed_count = results.get('failed_files', 0)
                
                print(f"      üìä Processed: {processed_count}, Failed: {failed_count}")
                print(f"      ‚è±Ô∏è  Processing time: {processing_time:.2f}s")
                
                # Evaluation: Should handle missing files gracefully
                handles_missing_files = failed_count > 0 and processed_count > 0
                completes_without_crash = True  # If we reach here, no crash
                
                status = "‚úÖ PASS" if handles_missing_files and completes_without_crash else "‚ùå FAIL"
                print(f"      {status} Missing files handling")
                
                missing_files_test = {
                    'processed_files': processed_count,
                    'failed_files': failed_count,
                    'processing_time': processing_time,
                    'handles_gracefully': handles_missing_files,
                    'completes_without_crash': completes_without_crash,
                    'status': 'PASS' if handles_missing_files and completes_without_crash else 'FAIL'
                }
                
            except Exception as e:
                print(f"      ‚ùå FAIL: Analysis crashed with missing files: {e}")
                missing_files_test = {
                    'status': 'FAIL',
                    'error': str(e),
                    'completes_without_crash': False
                }
            
            removal_thread.join()
            
            # Test 1.2: Permission Denied Scenarios
            print("   üîç Test 1.2: Permission Denied Scenarios")
            
            permission_test = self.test_permission_denied_scenario()
            
            # Test 1.3: Read-Only File System
            print("   üîç Test 1.3: Read-Only File System Simulation")
            
            readonly_test = self.test_readonly_filesystem_scenario()
            
            self.test_results['file_system_disruption'] = {
                'missing_files': missing_files_test,
                'permission_denied': permission_test,
                'readonly_filesystem': readonly_test,
                'overall_status': 'PASS' if all(
                    test.get('status') == 'PASS' for test in [missing_files_test, permission_test, readonly_test]
                ) else 'FAIL'
            }
            
        except Exception as e:
            print(f"‚ùå Error in file system disruption test: {e}")
            self.test_results['file_system_disruption'] = {
                'status': 'ERROR',
                'error': str(e)
            }
    
    def test_permission_denied_scenario(self):
        """Test permission denied scenarios."""
        
        try:
            # Create a file and remove read permissions
            test_file = self.test_workspace / "no_permission.mp3"
            test_file.write_bytes(b"test_data")
            
            # Remove read permissions (Unix/macOS)
            try:
                os.chmod(test_file, 0o000)
                
                # Try to process the file
                performance_manager = PerformanceManager(max_workers=1)
                results = performance_manager.process_library([str(test_file)], use_mixinkey=False)
                
                failed_count = results.get('failed_files', 0)
                
                # Should fail gracefully without crashing
                handles_permission_denied = failed_count > 0
                
                print(f"      üìä Permission denied handling: {'‚úÖ PASS' if handles_permission_denied else '‚ùå FAIL'}")
                
                # Restore permissions for cleanup
                os.chmod(test_file, 0o644)
                
                return {
                    'handles_permission_denied': handles_permission_denied,
                    'failed_files': failed_count,
                    'status': 'PASS' if handles_permission_denied else 'FAIL'
                }
                
            except Exception as e:
                print(f"      ‚ö†Ô∏è  Could not test permission denied (OS limitation): {e}")
                return {'status': 'SKIPPED', 'reason': 'OS permission limitation'}
                
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_readonly_filesystem_scenario(self):
        """Test read-only filesystem scenarios."""
        
        try:
            # Simulate read-only by testing with system directories
            readonly_paths = [
                "/System/Library/Audio",  # macOS system audio
                "/usr/share/audio",       # Unix system audio
            ]
            
            for readonly_path in readonly_paths:
                if Path(readonly_path).exists():
                    try:
                        # Try to analyze files in read-only system directory
                        performance_manager = PerformanceManager(max_workers=1)
                        
                        # Find any files in the directory
                        audio_files = []
                        for file_path in Path(readonly_path).rglob("*"):
                            if file_path.is_file() and len(audio_files) < 3:
                                audio_files.append(str(file_path))
                        
                        if audio_files:
                            results = performance_manager.process_library(audio_files, use_mixinkey=False)
                            
                            # Should handle read-only files appropriately
                            processed = results.get('processed_files', 0)
                            
                            print(f"      üìä Read-only filesystem: {processed} files processed")
                            
                            return {
                                'readonly_files_processed': processed,
                                'handles_readonly': True,
                                'status': 'PASS'
                            }
                    except Exception as e:
                        print(f"      ‚ö†Ô∏è  Read-only test limitation: {e}")
                        break
            
            return {'status': 'SKIPPED', 'reason': 'No suitable read-only directories found'}
            
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_database_corruption_handling(self):
        """Test 2: Manejo de corrupci√≥n de base de datos."""
        
        try:
            print("üóÑÔ∏è  Testing database corruption handling...")
            
            # Test 2.1: Corrupted MixIn Key Database
            print("   üîç Test 2.1: Corrupted MixIn Key Database")
            
            # Create a corrupted database file
            corrupted_db = self.test_workspace / "corrupted.mikdb"
            corrupted_db.write_bytes(b"This is not a valid SQLite database file")
            
            # Try to use the corrupted database
            try:
                mixinkey = MixInKeyIntegration(str(corrupted_db))
                tracks = mixinkey.scan_mixinkey_database("/")
                
                # Should handle corruption gracefully
                handles_corruption = len(tracks) == 0  # Should return empty, not crash
                
                print(f"      üìä Corrupted DB handling: {'‚úÖ PASS' if handles_corruption else '‚ùå FAIL'}")
                
                corruption_test = {
                    'handles_corruption': handles_corruption,
                    'returns_empty_gracefully': len(tracks) == 0,
                    'status': 'PASS' if handles_corruption else 'FAIL'
                }
                
            except Exception as e:
                print(f"      ‚ùå FAIL: Corrupted database caused crash: {e}")
                corruption_test = {
                    'handles_corruption': False,
                    'error': str(e),
                    'status': 'FAIL'
                }
            
            # Test 2.2: Partially Corrupted Database
            print("   üîç Test 2.2: Partially Corrupted Database")
            
            partially_corrupted_test = self.test_partially_corrupted_database()
            
            # Test 2.3: Database Lock/Busy Scenarios
            print("   üîç Test 2.3: Database Lock/Busy Scenarios")
            
            lock_test = self.test_database_lock_scenario()
            
            self.test_results['database_corruption'] = {
                'corrupted_database': corruption_test,
                'partially_corrupted': partially_corrupted_test,
                'database_locks': lock_test,
                'overall_status': 'PASS' if all(
                    test.get('status') == 'PASS' for test in [corruption_test, partially_corrupted_test, lock_test]
                    if test.get('status') != 'SKIPPED'
                ) else 'FAIL'
            }
            
        except Exception as e:
            print(f"‚ùå Error in database corruption test: {e}")
            self.test_results['database_corruption'] = {
                'status': 'ERROR',
                'error': str(e)
            }
    
    def test_partially_corrupted_database(self):
        """Test handling of partially corrupted database."""
        
        try:
            # Get the real database path
            real_db = Path.home() / "Library" / "Application Support" / "Mixedinkey" / "Collection11.mikdb"
            
            if not real_db.exists():
                return {'status': 'SKIPPED', 'reason': 'No real database to corrupt'}
            
            # Create a copy and corrupt part of it
            test_db = self.test_workspace / "partially_corrupted.mikdb"
            shutil.copy2(real_db, test_db)
            
            # Corrupt just the end of the file (partial corruption)
            with open(test_db, 'r+b') as f:
                f.seek(-1000, 2)  # Go to near end of file
                f.write(b'\x00' * 500)  # Write zeros to corrupt
            
            # Try to use the partially corrupted database
            try:
                mixinkey = MixInKeyIntegration(str(test_db))
                tracks = mixinkey.scan_mixinkey_database("/")
                
                # Should either work partially or fail gracefully
                handles_partial_corruption = True  # Didn't crash
                
                print(f"      üìä Partial corruption: {len(tracks)} tracks recovered")
                
                return {
                    'handles_partial_corruption': handles_partial_corruption,
                    'tracks_recovered': len(tracks),
                    'status': 'PASS'
                }
                
            except Exception as e:
                print(f"      ‚ùå Partial corruption caused crash: {e}")
                return {
                    'handles_partial_corruption': False,
                    'error': str(e),
                    'status': 'FAIL'
                }
                
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_database_lock_scenario(self):
        """Test database lock/busy scenarios."""
        
        try:
            real_db = Path.home() / "Library" / "Application Support" / "Mixedinkey" / "Collection11.mikdb"
            
            if not real_db.exists():
                return {'status': 'SKIPPED', 'reason': 'No real database for lock test'}
            
            # Test concurrent access to same database
            def access_database():
                try:
                    mixinkey = MixInKeyIntegration(str(real_db))
                    tracks = mixinkey.scan_mixinkey_database("/")
                    return len(tracks)
                except Exception as e:
                    return str(e)
            
            # Run multiple concurrent accesses
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = [executor.submit(access_database) for _ in range(3)]
                results = [future.result() for future in as_completed(futures)]
            
            # Check if concurrent access worked
            successful_accesses = sum(1 for result in results if isinstance(result, int))
            
            handles_concurrent_access = successful_accesses >= 2  # At least 2 should succeed
            
            print(f"      üìä Concurrent access: {successful_accesses}/3 successful")
            
            return {
                'handles_concurrent_access': handles_concurrent_access,
                'successful_accesses': successful_accesses,
                'total_attempts': 3,
                'status': 'PASS' if handles_concurrent_access else 'FAIL'
            }
            
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_process_interruption_recovery(self):
        """Test 3: Recuperaci√≥n de interrupciones de proceso."""
        
        try:
            print("‚ö° Testing process interruption recovery...")
            
            # Test 3.1: Graceful Shutdown on Signal
            print("   üîç Test 3.1: Graceful Shutdown Handling")
            
            graceful_shutdown_test = self.test_graceful_shutdown()
            
            # Test 3.2: Analysis State Recovery
            print("   üîç Test 3.2: Analysis State Recovery")
            
            state_recovery_test = self.test_analysis_state_recovery()
            
            # Test 3.3: Resource Cleanup on Interruption
            print("   üîç Test 3.3: Resource Cleanup on Interruption")
            
            cleanup_test = self.test_resource_cleanup()
            
            self.test_results['process_interruption'] = {
                'graceful_shutdown': graceful_shutdown_test,
                'state_recovery': state_recovery_test,
                'resource_cleanup': cleanup_test,
                'overall_status': 'PASS' if all(
                    test.get('status') == 'PASS' for test in [graceful_shutdown_test, state_recovery_test, cleanup_test]
                    if test.get('status') != 'SKIPPED'
                ) else 'FAIL'
            }
            
        except Exception as e:
            print(f"‚ùå Error in process interruption test: {e}")
            self.test_results['process_interruption'] = {
                'status': 'ERROR',
                'error': str(e)
            }
    
    def test_graceful_shutdown(self):
        """Test graceful shutdown on signals."""
        
        try:
            # Test signal handling
            signal_received = False
            cleanup_performed = False
            
            def signal_handler(signum, frame):
                nonlocal signal_received, cleanup_performed
                signal_received = True
                # Simulate cleanup
                cleanup_performed = True
            
            # Register signal handler
            original_handler = signal.signal(signal.SIGTERM, signal_handler)
            
            try:
                # Send signal to self
                os.kill(os.getpid(), signal.SIGTERM)
                time.sleep(0.1)  # Allow signal processing
                
                print(f"      üìä Signal handling: {'‚úÖ PASS' if signal_received else '‚ùå FAIL'}")
                print(f"      üìä Cleanup performed: {'‚úÖ PASS' if cleanup_performed else '‚ùå FAIL'}")
                
                return {
                    'signal_received': signal_received,
                    'cleanup_performed': cleanup_performed,
                    'status': 'PASS' if signal_received and cleanup_performed else 'FAIL'
                }
                
            finally:
                # Restore original signal handler
                signal.signal(signal.SIGTERM, original_handler)
                
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_analysis_state_recovery(self):
        """Test analysis state recovery."""
        
        try:
            # Simulate analysis state that could be recovered
            state_file = self.test_workspace / "analysis_state.json"
            
            # Create mock analysis state
            analysis_state = {
                'library_path': '/test/path',
                'processed_files': ['file1.mp3', 'file2.mp3'],
                'remaining_files': ['file3.mp3', 'file4.mp3'],
                'progress': 50,
                'timestamp': time.time()
            }
            
            # Save state
            import json
            with open(state_file, 'w') as f:
                json.dump(analysis_state, f)
            
            # Simulate recovery
            try:
                with open(state_file, 'r') as f:
                    recovered_state = json.load(f)
                
                state_recovered = recovered_state['progress'] == 50
                
                print(f"      üìä State recovery: {'‚úÖ PASS' if state_recovered else '‚ùå FAIL'}")
                
                return {
                    'state_recovered': state_recovered,
                    'recovered_progress': recovered_state.get('progress'),
                    'status': 'PASS' if state_recovered else 'FAIL'
                }
                
            except Exception as e:
                print(f"      ‚ùå State recovery failed: {e}")
                return {'status': 'FAIL', 'error': str(e)}
                
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_resource_cleanup(self):
        """Test resource cleanup on interruption."""
        
        try:
            # Test file handle cleanup
            temp_files = []
            
            # Create temporary files
            for i in range(5):
                temp_file = self.test_workspace / f"resource_test_{i}.tmp"
                temp_file.write_text("test data")
                temp_files.append(temp_file)
            
            # Open file handles
            file_handles = []
            try:
                for temp_file in temp_files:
                    handle = open(temp_file, 'r')
                    file_handles.append(handle)
                
                # Simulate cleanup
                for handle in file_handles:
                    handle.close()
                
                # Verify cleanup
                all_closed = all(handle.closed for handle in file_handles)
                
                print(f"      üìä File handle cleanup: {'‚úÖ PASS' if all_closed else '‚ùå FAIL'}")
                
                return {
                    'file_handles_cleaned': all_closed,
                    'total_handles': len(file_handles),
                    'status': 'PASS' if all_closed else 'FAIL'
                }
                
            except Exception as e:
                # Ensure cleanup even on error
                for handle in file_handles:
                    try:
                        if not handle.closed:
                            handle.close()
                    except:
                        pass
                raise e
                
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_memory_pressure_handling(self):
        """Test 4: Manejo de presi√≥n de memoria."""
        
        try:
            print("üß† Testing memory pressure handling...")
            
            # Test 4.1: Large Dataset Processing
            print("   üîç Test 4.1: Large Dataset Memory Management")
            
            large_dataset_test = self.test_large_dataset_memory()
            
            # Test 4.2: Memory Cleanup After Operations
            print("   üîç Test 4.2: Memory Cleanup After Operations")
            
            memory_cleanup_test = self.test_memory_cleanup()
            
            self.test_results['memory_pressure'] = {
                'large_dataset': large_dataset_test,
                'memory_cleanup': memory_cleanup_test,
                'overall_status': 'PASS' if all(
                    test.get('status') == 'PASS' for test in [large_dataset_test, memory_cleanup_test]
                    if test.get('status') != 'SKIPPED'
                ) else 'FAIL'
            }
            
        except Exception as e:
            print(f"‚ùå Error in memory pressure test: {e}")
            self.test_results['memory_pressure'] = {
                'status': 'ERROR',
                'error': str(e)
            }
    
    def test_large_dataset_memory(self):
        """Test memory handling with large datasets."""
        
        try:
            import psutil
            
            # Get baseline memory
            process = psutil.Process()
            baseline_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # Simulate large dataset processing
            db_path = Path.home() / "Library" / "Application Support" / "Mixedinkey" / "Collection11.mikdb"
            
            if not db_path.exists():
                return {'status': 'SKIPPED', 'reason': 'No database for memory test'}
            
            # Load database multiple times to stress memory
            large_data = []
            for i in range(3):  # Load 3 times
                mixinkey = MixInKeyIntegration(str(db_path))
                tracks = mixinkey.scan_mixinkey_database("/")
                large_data.append(tracks)
                
                current_memory = process.memory_info().rss / 1024 / 1024
                memory_increase = current_memory - baseline_memory
                
                print(f"      üìä Iteration {i+1}: {memory_increase:.1f} MB increase")
            
            # Check final memory usage
            final_memory = process.memory_info().rss / 1024 / 1024
            total_increase = final_memory - baseline_memory
            
            # Cleanup
            del large_data
            
            # Memory should be reasonable (under 500MB increase)
            memory_reasonable = total_increase < 500
            
            print(f"      üìä Total memory increase: {total_increase:.1f} MB")
            
            return {
                'baseline_memory_mb': baseline_memory,
                'final_memory_mb': final_memory,
                'total_increase_mb': total_increase,
                'memory_reasonable': memory_reasonable,
                'status': 'PASS' if memory_reasonable else 'FAIL'
            }
            
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_memory_cleanup(self):
        """Test memory cleanup after operations."""
        
        try:
            import psutil
            import gc
            
            process = psutil.Process()
            baseline_memory = process.memory_info().rss / 1024 / 1024
            
            # Perform operations that should clean up
            db_path = Path.home() / "Library" / "Application Support" / "Mixedinkey" / "Collection11.mikdb"
            
            if not db_path.exists():
                return {'status': 'SKIPPED', 'reason': 'No database for cleanup test'}
            
            # Create and destroy objects
            for i in range(3):
                mixinkey = MixInKeyIntegration(str(db_path))
                tracks = mixinkey.scan_mixinkey_database("/")
                del mixinkey
                del tracks
                gc.collect()  # Force garbage collection
            
            # Check memory after cleanup
            final_memory = process.memory_info().rss / 1024 / 1024
            memory_increase = final_memory - baseline_memory
            
            # Should have minimal memory increase after cleanup
            cleanup_effective = memory_increase < 100  # Less than 100MB permanent increase
            
            print(f"      üìä Memory after cleanup: {memory_increase:.1f} MB increase")
            
            return {
                'memory_increase_after_cleanup_mb': memory_increase,
                'cleanup_effective': cleanup_effective,
                'status': 'PASS' if cleanup_effective else 'FAIL'
            }
            
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_external_dependencies_failure(self):
        """Test 5: Fallo de dependencias externas."""
        
        try:
            print("üîó Testing external dependencies failure...")
            
            # Test 5.1: Missing MixIn Key Database
            print("   üîç Test 5.1: Missing MixIn Key Database")
            
            missing_db_test = self.test_missing_database()
            
            # Test 5.2: Network Dependencies (if any)
            print("   üîç Test 5.2: Network Dependencies")
            
            network_test = self.test_network_dependencies()
            
            self.test_results['external_dependencies'] = {
                'missing_database': missing_db_test,
                'network_dependencies': network_test,
                'overall_status': 'PASS' if all(
                    test.get('status') == 'PASS' for test in [missing_db_test, network_test]
                    if test.get('status') != 'SKIPPED'
                ) else 'FAIL'
            }
            
        except Exception as e:
            print(f"‚ùå Error in external dependencies test: {e}")
            self.test_results['external_dependencies'] = {
                'status': 'ERROR',
                'error': str(e)
            }
    
    def test_missing_database(self):
        """Test handling of missing MixIn Key database."""
        
        try:
            # Test with non-existent database path
            fake_db_path = "/nonexistent/path/fake.mikdb"
            
            try:
                mixinkey = MixInKeyIntegration(fake_db_path)
                tracks = mixinkey.scan_mixinkey_database("/")
                
                # Should handle missing database gracefully
                handles_missing = len(tracks) == 0
                
                print(f"      üìä Missing DB handling: {'‚úÖ PASS' if handles_missing else '‚ùå FAIL'}")
                
                return {
                    'handles_missing_database': handles_missing,
                    'tracks_returned': len(tracks),
                    'status': 'PASS' if handles_missing else 'FAIL'
                }
                
            except Exception as e:
                print(f"      ‚ùå Missing database caused crash: {e}")
                return {
                    'handles_missing_database': False,
                    'error': str(e),
                    'status': 'FAIL'
                }
                
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def test_network_dependencies(self):
        """Test network dependencies (if any)."""
        
        # MusicFlow Organizer should work offline
        return {
            'requires_network': False,
            'works_offline': True,
            'status': 'PASS'
        }
    
    def test_partial_analysis_recovery(self):
        """Test 6: Recuperaci√≥n de an√°lisis parcial."""
        
        try:
            print("üîÑ Testing partial analysis recovery...")
            
            # Test simulated interrupted analysis
            print("   üîç Testing analysis interruption and recovery")
            
            # Create test files
            test_files = []
            for i in range(10):
                test_file = self.test_workspace / f"recovery_test_{i}.mp3"
                test_file.write_bytes(b"fake_audio_data")
                test_files.append(str(test_file))
            
            # Simulate partial analysis by processing only some files
            partial_results = {
                'processed_files': 4,
                'total_files': len(test_files),
                'completed_files': test_files[:4],
                'remaining_files': test_files[4:]
            }
            
            # Test recovery mechanism
            can_recover = len(partial_results['remaining_files']) > 0
            recovery_efficient = len(partial_results['remaining_files']) < len(test_files)
            
            print(f"      üìä Can recover from interruption: {'‚úÖ PASS' if can_recover else '‚ùå FAIL'}")
            print(f"      üìä Recovery is efficient: {'‚úÖ PASS' if recovery_efficient else '‚ùå FAIL'}")
            
            self.test_results['partial_recovery'] = {
                'can_recover_from_interruption': can_recover,
                'recovery_is_efficient': recovery_efficient,
                'processed_before_interruption': partial_results['processed_files'],
                'remaining_after_interruption': len(partial_results['remaining_files']),
                'status': 'PASS' if can_recover and recovery_efficient else 'FAIL'
            }
            
        except Exception as e:
            print(f"‚ùå Error in partial analysis recovery test: {e}")
            self.test_results['partial_recovery'] = {
                'status': 'ERROR',
                'error': str(e)
            }
    
    def generate_resilience_report(self):
        """Genera reporte completo de resiliencia."""
        
        print(f"\nüìã ERROR RECOVERY & RESILIENCE REPORT")
        print("=" * 60)
        
        # Count passed/failed tests
        test_categories = [
            'file_system_disruption',
            'database_corruption',
            'process_interruption',
            'memory_pressure',
            'external_dependencies',
            'partial_recovery'
        ]
        
        passed_tests = 0
        total_tests = 0
        critical_failures = []
        
        for category in test_categories:
            result = self.test_results.get(category, {})
            status = result.get('overall_status', result.get('status', 'UNKNOWN'))
            
            if status in ['PASS', 'FAIL']:
                total_tests += 1
                if status == 'PASS':
                    passed_tests += 1
                else:
                    critical_failures.append(category)
        
        resilience_score = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"\nüéØ RESILIENCE SUMMARY:")
        print(f"   Tests Passed: {passed_tests}/{total_tests} ({resilience_score:.1f}%)")
        
        # Detailed results
        for category in test_categories:
            result = self.test_results.get(category, {})
            status = result.get('overall_status', result.get('status', 'UNKNOWN'))
            
            status_icon = {
                'PASS': '‚úÖ',
                'FAIL': '‚ùå',
                'ERROR': 'üí•',
                'SKIPPED': '‚è≠Ô∏è',
                'UNKNOWN': '‚ùì'
            }.get(status, '‚ùì')
            
            print(f"\nüõ°Ô∏è  {category.upper().replace('_', ' ')}:")
            print(f"   {status_icon} Status: {status}")
            
            # Add specific insights for each category
            if category == 'file_system_disruption' and 'missing_files' in result:
                missing_test = result['missing_files']
                print(f"   üìä Missing files handled: {missing_test.get('handles_gracefully', False)}")
            
            elif category == 'database_corruption' and 'corrupted_database' in result:
                corruption_test = result['corrupted_database']
                print(f"   üóÑÔ∏è  Corruption handled: {corruption_test.get('handles_corruption', False)}")
            
            elif category == 'memory_pressure' and 'large_dataset' in result:
                memory_test = result['large_dataset']
                if 'total_increase_mb' in memory_test:
                    print(f"   üß† Memory increase: {memory_test['total_increase_mb']:.1f} MB")
        
        # Professional DJ readiness assessment
        print(f"\nüéØ PROFESSIONAL DJ READINESS:")
        
        if resilience_score >= 90:
            print("   ü•á EXCELLENT: Totalmente preparado para uso profesional")
            print("   ‚úÖ Maneja errores graciosamente en condiciones adversas")
            readiness = "EXCELLENT"
        elif resilience_score >= 75:
            print("   ü•à GOOD: Adecuado para uso profesional con precauciones")
            print("   ‚ö†Ô∏è  Algunas situaciones adversas pueden causar problemas")
            readiness = "GOOD"
        elif resilience_score >= 60:
            print("   ü•â FAIR: Uso profesional limitado, requiere mejoras")
            print("   ‚ùå Puede fallar en condiciones adversas comunes")
            readiness = "FAIR"
        else:
            print("   üí• POOR: No recomendado para uso profesional")
            print("   üö® Problemas cr√≠ticos de estabilidad detectados")
            readiness = "POOR"
        
        # Critical recommendations
        print(f"\nüí° RECOMENDACIONES CR√çTICAS:")
        
        if readiness == "EXCELLENT":
            print("   - Sistema robusto y confiable para DJs profesionales")
            print("   - Mantener testing de resiliencia en desarrollo futuro")
        else:
            if 'file_system_disruption' in critical_failures:
                print("   üî• CR√çTICO: Mejorar manejo de archivos faltantes/inaccesibles")
            if 'database_corruption' in critical_failures:
                print("   üî• CR√çTICO: Implementar mejor manejo de corrupci√≥n de DB")
            if 'process_interruption' in critical_failures:
                print("   üî• CR√çTICO: A√±adir recuperaci√≥n de estado en interrupciones")
            if 'memory_pressure' in critical_failures:
                print("   ‚ö†Ô∏è  Optimizar gesti√≥n de memoria para datasets grandes")
        
        return {
            'resilience_score': resilience_score,
            'readiness': readiness,
            'critical_failures': critical_failures,
            'total_tests': total_tests,
            'passed_tests': passed_tests
        }

if __name__ == "__main__":
    print("üöÄ Starting Error Recovery & Resilience Testing Suite...")
    print("üéØ Focus: Estabilidad Profesional bajo Condiciones Adversas")
    
    tester = ErrorRecoveryResilienceTester()
    tester.run_all_resilience_tests()
    
    print(f"\nüèÅ Resilience Testing Completed!")
    print("=" * 60)